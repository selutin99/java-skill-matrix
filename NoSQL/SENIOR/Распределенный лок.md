# Как реализовать распределенный лок

## 1. Базовые принципы распределённого лока

* **Цель**: гарантировать, что только один процесс/инстанс выполняет «критическую секцию».
* **Требования**: уникальность владельца, TTL (авто-освобождение при сбое), продление (heartbeat), безопасный релиз (только владелец снимает), защита от split-brain.
* **Ключевые техники**: `SET NX PX` (Redis), эфемерные узлы (ZooKeeper), сессии/leases (etcd/Consul), «фехтовальные токены» (fencing tokens), идемпотентность операций.

---

## 2. Реализация на Redis: минимальный и безопасный вариант

### 2.1. Принцип

* Захват: атомарный `SET key value NX PX <ttl_ms>`.
* Продление: периодическое обновление TTL (если владелец всё ещё активен).
* Освобождение: **сравнить value и удалить** (иначе можно удалить чужой лок). Делается через Lua-скрипт.

### 2.2. Код (Lettuce/Jedis) — acquire/release

```java
// value = уникальный идентификатор владельца (UUID)
String lockKey = "lock:order:123";
String owner = UUID.randomUUID().toString();
long ttlMs = 15000;

// acquire
String ok = redis.sync().set(lockKey, owner, SetArgs.Builder.nx().px(ttlMs));
if (!"OK".equals(ok)) throw new IllegalStateException("Lock busy");

// ... критическая секция ...

// safe release (compare-and-del)
String lua =
  "if redis.call('get', KEYS[1]) == ARGV[1] then " +
  "  return redis.call('del', KEYS[1]) " +
  "else return 0 end";
redis.sync().eval(lua, ScriptOutputType.INTEGER, new String[]{lockKey}, owner);
```

**Что учесть**

* Держите watchdog/heartbeat для долгих операций (продлевайте TTL).
* На ошибки сети реагируйте как на «неизвестно, владею ли локом» → лучше повторить безопасно (идемпотентность).

### 2.3. Redisson (проще)

```java
// конфигурация RedissonClient и бин опущены
RLock lock = redissonClient.getLock("lock:order:123");
boolean acquired = lock.tryLock(5, 15, TimeUnit.SECONDS); // wait=5s, lease=15s
try {
  if (!acquired) throw new IllegalStateException("Lock busy");
  // критическая секция
} finally {
  if (lock.isHeldByCurrentThread()) lock.unlock();
}
```

> Преимущества: авто-продление, reentrant-поведение, справедливые логи, семафоры и др.

**Замечание про Redlock**: алгоритм Redis-Redlock (несколько независимых Redis) встречает критику в жёстких SLA. Для бизнес-критичных денежных операций лучше ZooKeeper/etcd.

---

## 3. ZooKeeper / Curator: эпемерные последовательные узлы

### 3.1. Принцип

* Клиент создаёт **ephemeral sequential node** в директории лока `/locks/mylock/lock-000000X`.
* Владелец — тот, у кого **минимальный номер**. Остальные ставят watcher на предыдущий узел и ждут.
* Сессия упала → узел удаляется автоматически (лок освобождён).

### 3.2. Код (Apache Curator)

```java
InterProcessMutex lock = new InterProcessMutex(curator, "/locks/mylock");
if (lock.acquire(10, TimeUnit.SECONDS)) {
  try {
    // критическая секция
  } finally {
    lock.release();
  }
}
```

**Плюсы**: сильные гарантийные свойства, автоматическое освобождение при падении.
**Минусы**: отдельный кластер ZK, чуть сложнее эксплуатация.

---

## 4. etcd / Consul: lock через сессии/lease

* **etcd**: `lease + put-if-absent` (CAS) и keep-alive; потеряли lease → ключ удалится.
* **Consul**: `session` + `KV acquire/release`.
  Под капотом — тот же паттерн «ключ с арендой и heartbeat».

---

## 5. Реляционная БД: когда можно обойтись без внешнего хранилища

1. **Advisory locks** (PostgreSQL `pg_try_advisory_lock`) — лёгко и быстро в пределах одного кластера БД.
2. **Уникальный ключ** как лок: вставка «маячка» в таблицу; конфликт уникальности = лок занят.
3. `SELECT ... FOR UPDATE SKIP LOCKED` для очередей/воркеров.

> Подход жизнеспособен, если у вас один надёжный кластер БД и не хочется тянуть Redis/ZK.

---

## 6. Фехтовальные токены (fencing tokens) — защита от split-brain

Даже с локом возможна ситуация «старый владелец ещё пишет» после того, как лок у него отобрали (GC stop-the-world, сетевой лаг).
**Идея**: при выдаче лока увеличивать **монотонный счётчик** (token). Каждая операция на ресурсе проверяет, что `token` актуален. Старый владелец с меньшим токеном отклоняется.

* В Redis храните `token` рядом с lock-ключом;
* В ZK — версия узла;
* На ресурсном уровне — валидируйте токен в БД/сервисе.

---

## 7. Паттерны надёжности и антипаттерны

**Делайте**

* TTL + продление (watchdog).
* Безопасный release (compare-and-delete).
* Идемпотентные операции внутри лока.
* Таймауты и backoff на acquire.
* Метрики: время удержания, отказов, продлений.

**Не делайте**

* `DEL lock` без проверки владельца.
* Бесконечные локации без TTL.
* Долгие I/O внутри лока без watchdog.
* Критичные деньги-операции только на простом Redis-локе — лучше ZK/etcd.

---

## 8. Быстрые рецепты выбора

* **Нужно просто и быстро** → Redis + Redisson (большинство кейсов).
* **Финансы/строгие гарантии/лидер-элекция** → ZooKeeper (Curator) или etcd.
* **Нет внешних систем** и один кластер БД → Postgres advisory locks.
* **Kubernetes-приложение** → leader-election через Lease API (client-go/Java операторы), а для критических секций внутри — Redis/ZK.

---

## 9. Выжимка для собеседования

* Распределённый лок = эксклюзивный доступ к ресурсу в кластере.
* Реализации: **Redis (SET NX PX + Lua / Redisson)**, **ZooKeeper (ephemeral sequential + Curator)**, **etcd/Consul (lease/session)**, **RDBMS advisory locks**.
* Гарантии обеспечиваются через: **TTL**, **heartbeat**, **safe release**, **fencing tokens**.
* Выбор инструмента зависит от критичности, латентности и доступной инфраструктуры.
