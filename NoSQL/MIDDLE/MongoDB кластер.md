# Как устроен шардированный кластер MongoDB и как обеспечивается отказоустойчивость

## 1. Архитектура шардированного кластера MongoDB

1. **Shard (шард)**

    * Хранит часть данных.
    * Обычно — это **реплика-сет** (несколько узлов, обеспечивающих отказоустойчивость).
    * Данные распределяются по шардам с помощью **shard key** (ключ шардирования).

2. **Config Servers (конфигурационные серверы)**

    * Минимум 3 узла.
    * Хранят метаданные: список шардов, распределение данных, информацию о чанках.
    * Критичны для работы кластера — без них система не сможет выполнять маршрутизацию.

3. **Mongos (query router)**

    * Лёгкий процесс, к которому подключаются клиенты.
    * Принимает запросы и определяет, на какие шарды их направить (по shard key).
    * Скрывает от приложения распределённую природу кластера.

---

## 2. Как распределяются данные

1. **Shard key**

    * Поле документа, по которому MongoDB определяет, на какой шард поместить запись.
    * Выбирается при создании шардированного коллекции и менять его нельзя.

2. **Chunks (чанки)**

    * Данные делятся на диапазоны (чанки).
    * MongoDB автоматически балансирует чанки между шардами, чтобы нагрузка распределялась равномерно.

3. **Маршрутизация**

    * Если запрос содержит shard key → `mongos` сразу идёт на конкретный шард.
    * Если shard key нет → запрос превращается в **scatter-gather** (отправляется на все шарды и объединяется).

---

## 3. Отказоустойчивость

1. **Replica Set внутри шарда**

    * Каждый шард — это **реплика-сет** (Primary + Secondaries).
    * **Primary** принимает запись, **Secondary** синхронизируются и могут обслуживать чтение (если разрешено).
    * При сбое Primary → автоматическое **переизбрание** нового Primary.

2. **Config Servers**

    * Хранятся в виде реплика-сета из 3+ серверов.
    * Если один падает → кластер продолжает работать.

3. **Mongos**

    * Лёгкий процесс, обычно разворачивается на каждом приложении-сервере.
    * Можно поднять несколько mongos для отказоустойчивости (клиенты могут переключаться).

4. **Балансировка и failover**

    * Если шард перегружен или выходит из строя → чанки перераспределяются на другие шарды.
    * Чтение/запись продолжает работать через другие узлы реплика-сета.

---

## 4. Выжимка для собеседования

* **Шардированный кластер MongoDB** = `mongos` (роутеры) + `config servers` (метаданные) + `shards` (данные).
* **Шард** = реплика-сет (Primary + Secondaries).
* Данные делятся на **чанки**, которые распределяются между шардами по **shard key**.
* **Отказоустойчивость**:

    * Внутри шарда — за счёт реплика-сета и автоматического failover.
    * Конфигурация хранится в реплика-сете config-серверов.
    * Несколько `mongos` обеспечивают доступ даже при сбоях роутеров.
* Преимущество: горизонтальное масштабирование + высокая доступность.
