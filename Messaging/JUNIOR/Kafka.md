# Что такое Kafka, для чего она используется, из каких компонентов состоит кластер

## 1. Что это такое

Apache Kafka — это распределённая платформа потоковой передачи данных (event streaming platform), изначально разработанная в LinkedIn.
Она предназначена для работы с большими объёмами сообщений в реальном времени: их публикации, хранения, обработки и доставки.

---

## 2. Для чего используется

Kafka применяется там, где нужно:

* **Передача событий в реальном времени** между сервисами (event-driven архитектура).
* **Интеграция микросервисов** — вместо REST или gRPC используют обмен сообщениями через Kafka.
* **Хранение логов и событий** (например, клики пользователей, действия в приложении).
* **Потоковая обработка данных** (real-time analytics).
* **Буферизация данных** перед записью в хранилище (например, в Data Lake или базу данных).
* **Замена очередей сообщений** (альтернатива RabbitMQ, ActiveMQ).

---

## 3. Основные компоненты кластера Kafka

1. **Producer**
   Отправитель сообщений (событий) в Kafka. Продюсер пишет данные в топики.

2. **Consumer**
   Получатель сообщений. Подписывается на один или несколько топиков и читает сообщения. Обычно объединяются в consumer groups для масштабирования.

3. **Topic**
   Логическая сущность для хранения сообщений.

    * Делится на **partitions** (разделы) для параллелизма и отказоустойчивости.
    * Сообщения в partition упорядочены.

4. **Broker**
   Узел кластера Kafka, хранящий данные топиков (разделов). Один брокер способен обрабатывать десятки/сотни тысяч сообщений в секунду.

5. **Cluster**
   Набор брокеров, которые работают совместно. Данные распределяются между брокерами для балансировки и репликации.

6. **Zookeeper** (в старых версиях)
   Использовался для координации кластера, хранения метаданных (какой брокер за какой раздел отвечает).
   ➝ В новых версиях Kafka (с KRaft mode) Zookeeper заменён встроенным **Kafka Controller**.

7. **Kafka Controller (KRaft)**
   Новый встроенный механизм управления кластером без Zookeeper. Контроллер управляет метаданными, назначает лидеров партиций.

8. **Schema Registry** (опционально, но часто используется)
   Компонент Confluent, где хранятся схемы сообщений (Avro, JSON Schema, Protobuf).
   Позволяет гарантировать совместимость продюсеров и консумеров.

9. **Kafka Connect**
   Фреймворк для интеграции Kafka с внешними системами (БД, Elasticsearch, S3 и т.д.). Есть готовые коннекторы.

10. **Kafka Streams / ksqlDB**
    Инструменты для обработки данных прямо в Kafka:

    * Kafka Streams — Java-библиотека для стрим-процессинга.
    * ksqlDB — SQL-подобный язык для работы с потоками.

---

## 4. Выжимка для собеседования

* **Kafka** — это распределённая платформа потоковой передачи событий.
* Она нужна для **реального времени**: интеграция микросервисов, обработка логов, аналитика, очереди сообщений.
* Кластер Kafka состоит из **брокеров**, которые хранят **топики** (разделённые на **partition**).
* Данные пишут **producers**, читают **consumers** (объединяются в группы).
* В старых версиях координацию выполнял **Zookeeper**, в новых — **Kafka Controller (KRaft)**.
* Дополнительно: **Schema Registry**, **Kafka Connect**, **Kafka Streams**.
